"""
ä¸ƒç‰›å®æ—¶è¯­éŸ³è¯†åˆ«æ¨¡å—
æ–‡æ¡£: https://developer.qiniu.com/dora/8084/real-time-speech-recognition
"""

import json
import base64
import hmac
import hashlib
import time
from typing import Optional, Dict, Any
import httpx


class QiniuVoiceRecognizer:
    """ä¸ƒç‰›å®æ—¶è¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯"""
    
    def __init__(self, access_key: str, secret_key: str):
        """
        åˆå§‹åŒ–ä¸ƒç‰›è¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯
        
        Args:
            access_key: ä¸ƒç‰› Access Key
            secret_key: ä¸ƒç‰› Secret Key
        """
        self.access_key = access_key
        self.secret_key = secret_key
        self.api_url = "https://ap-gate-z0.qiniuapi.com/asr/v1/audio"
        self.client = httpx.AsyncClient(timeout=60.0)
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.client.aclose()
    
    def _generate_token(self, method: str, path: str, body: bytes = b"") -> str:
        """
        ç”Ÿæˆä¸ƒç‰›è®¤è¯ Token
        
        Args:
            method: HTTP æ–¹æ³•
            path: è¯·æ±‚è·¯å¾„
            body: è¯·æ±‚ä½“
            
        Returns:
            è®¤è¯ Token
        """
        data = f"{method} {path}\nHost: ap-gate-z0.qiniuapi.com\nContent-Type: application/json\n\n"
        
        if body:
            data += body.decode("utf-8")
        
        sign = hmac.new(
            self.secret_key.encode("utf-8"),
            data.encode("utf-8"),
            hashlib.sha1
        ).digest()
        
        encoded_sign = base64.urlsafe_b64encode(sign).decode("utf-8")
        
        return f"Qiniu {self.access_key}:{encoded_sign}"
    
    async def recognize_audio_file(
        self,
        audio_data: bytes,
        audio_format: str = "wav",
        sample_rate: int = 16000,
        language: str = "zh-CN"
    ) -> str:
        """
        è¯†åˆ«éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆå­—èŠ‚ï¼‰
            audio_format: éŸ³é¢‘æ ¼å¼ (wav, mp3, pcm)
            sample_rate: é‡‡æ ·ç‡ (8000 æˆ– 16000)
            language: è¯­è¨€ (zh-CN æˆ– en-US)
            
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        audio_base64 = base64.b64encode(audio_data).decode("utf-8")
        
        request_body = {
            "audio": audio_base64,
            "format": audio_format,
            "rate": sample_rate,
            "language": language
        }
        
        body_bytes = json.dumps(request_body).encode("utf-8")
        
        token = self._generate_token("POST", "/asr/v1/audio", body_bytes)
        
        headers = {
            "Authorization": token,
            "Content-Type": "application/json"
        }
        
        try:
            response = await self.client.post(
                self.api_url,
                content=body_bytes,
                headers=headers
            )
            response.raise_for_status()
            
            result = response.json()
            
            if "result" in result and len(result["result"]) > 0:
                return result["result"][0].get("text", "")
            
            raise Exception("è¯­éŸ³è¯†åˆ«ç»“æœä¸ºç©º")
        
        except httpx.HTTPStatusError as e:
            raise Exception(f"HTTP Error: {e.response.status_code} - {e.response.text}")
        except Exception as e:
            raise Exception(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")
    
    async def recognize_url(
        self,
        audio_url: str,
        audio_format: str = "wav",
        sample_rate: int = 16000,
        language: str = "zh-CN"
    ) -> str:
        """
        è¯†åˆ«åœ¨çº¿éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_url: éŸ³é¢‘æ–‡ä»¶ URL
            audio_format: éŸ³é¢‘æ ¼å¼
            sample_rate: é‡‡æ ·ç‡
            language: è¯­è¨€
            
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        async with httpx.AsyncClient() as client:
            audio_response = await client.get(audio_url)
            audio_response.raise_for_status()
            audio_data = audio_response.content
        
        return await self.recognize_audio_file(audio_data, audio_format, sample_rate, language)


class LocalMicrophoneRecorder:
    """æœ¬åœ°éº¦å…‹é£å½•éŸ³å™¨ï¼ˆä½¿ç”¨ sounddeviceï¼‰"""
    
    def __init__(self, sample_rate: int = 16000, channels: int = 1):
        """
        åˆå§‹åŒ–éº¦å…‹é£å½•éŸ³å™¨
        
        Args:
            sample_rate: é‡‡æ ·ç‡
            channels: å£°é“æ•°
        """
        self.sample_rate = sample_rate
        self.channels = channels
    
    def record_audio(self, duration: int = 5) -> bytes:
        """
        å½•åˆ¶éŸ³é¢‘
        
        Args:
            duration: å½•åˆ¶æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            éŸ³é¢‘æ•°æ®ï¼ˆWAV æ ¼å¼ï¼‰
        """
        try:
            import sounddevice as sd
            import numpy as np
            import wave
            import io
            
            print(f"ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆ{duration} ç§’ï¼‰...")
            
            audio = sd.rec(
                int(duration * self.sample_rate),
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype=np.int16
            )
            sd.wait()
            
            print("âœ… å½•éŸ³å®Œæˆ")
            
            buffer = io.BytesIO()
            with wave.open(buffer, 'wb') as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(2)
                wf.setframerate(self.sample_rate)
                wf.writeframes(audio.tobytes())
            
            return buffer.getvalue()
        
        except ImportError:
            raise Exception(
                "sounddevice æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install sounddevice numpy"
            )
        except Exception as e:
            raise Exception(f"å½•éŸ³å¤±è´¥: {str(e)}")


class MockVoiceRecognizer:
    """æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«å™¨ - ç”¨äºå¼€å‘æµ‹è¯•"""
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        pass
    
    async def recognize_audio_file(
        self,
        audio_data: bytes,
        audio_format: str = "wav",
        sample_rate: int = 16000,
        language: str = "zh-CN"
    ) -> str:
        """æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«"""
        print("âš ï¸  ä½¿ç”¨ Mock è¯­éŸ³è¯†åˆ«æ¨¡å¼")
        return "ä»åŒ—äº¬åˆ°ä¸Šæµ·"


def create_voice_recognizer(config: Dict[str, Any]):
    """
    åˆ›å»ºè¯­éŸ³è¯†åˆ«å™¨
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        QiniuVoiceRecognizer æˆ– MockVoiceRecognizer å®ä¾‹
    """
    qiniu_config = config.get("qiniu", {})
    access_key = qiniu_config.get("accessKey", "")
    secret_key = qiniu_config.get("secretKey", "")
    
    if not access_key or not secret_key or "YOUR_QINIU" in access_key:
        print("âš ï¸  æœªé…ç½®ä¸ƒç‰›å¯†é’¥ï¼Œè¯­éŸ³è¯†åˆ«å°†ä½¿ç”¨ Mock æ¨¡å¼")
        return MockVoiceRecognizer()
    
    print("âœ… åˆå§‹åŒ–ä¸ƒç‰›è¯­éŸ³è¯†åˆ«...")
    return QiniuVoiceRecognizer(access_key, secret_key)
